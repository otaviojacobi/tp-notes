{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import random\n",
    "from random import choice\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATIONS = ['relu', 'sigmoid', 'softmax', 'tanh', 'elu']\n",
    "\n",
    "class Individual:\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"\n",
    "        An individual is in the form of a 11 values vector\n",
    "        [n0, n1, n2, n3, n4, n5, n6, n7, n8, n9] where\n",
    "        [n0-n4] are the amount of neurons per layer\n",
    "        [n5-n9] are the activation function on each layer\n",
    "        n10 is the activation function on the last layer\n",
    "        \n",
    "        If any neuron in n0-n4 is 0, it's like having less layers\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        self.config = self.__generate_random() if config == None else config\n",
    "        self.nn = self.__build_nn()\n",
    "        self._initial_w = self.nn.get_weights()\n",
    "\n",
    "    \n",
    "    def __build_nn(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        for idx, neurons in enumerate(self.config[:5]):\n",
    "            if idx == 0:\n",
    "                model.add(Dense(neurons, activation=self.config[5], input_shape=(784,)))\n",
    "            \n",
    "            if neurons != 0:\n",
    "                model.add(Dense(neurons, activation=self.config[5]))\n",
    "            \n",
    "        model.add(Dense(10, activation=self.config[-1]))\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def __generate_random(self):\n",
    "\n",
    "        return [\n",
    "            random.randint(1, 64),\n",
    "            random.randint(0, 64),\n",
    "            random.randint(0, 64),\n",
    "            random.randint(0, 64),\n",
    "            random.randint(0, 64),\n",
    "            choice(ACTIVATIONS),\n",
    "            choice(ACTIVATIONS),\n",
    "        ]\n",
    "    \n",
    "    def fitness(self, X_train, y_train, X_test, y_test):\n",
    "        self.nn.set_weights(self._initial_w)\n",
    "\n",
    "        history = self.nn.fit(X_train, \n",
    "                              y_train, \n",
    "                              epochs=4, \n",
    "                              batch_size=256, \n",
    "                              verbose=0,\n",
    "                              validation_data=(X_test, y_test))\n",
    "\n",
    "        acc = history.history['accuracy'][-1]\n",
    "        val_acc = history.history['val_accuracy'][-1]\n",
    "        \n",
    "        print(acc)\n",
    "        print(val_acc)\n",
    "        \n",
    "        return acc\n",
    "        \n",
    "\n",
    "class AutoML:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # AutML hyperparameters\n",
    "        self.SIZE = 10\n",
    "        self.RETAIN = 0.5\n",
    "        self.GENERATIONS = 10\n",
    "        self.MUTATION_RATE = 0.10\n",
    "        \n",
    "        self._retain_int = int(self.SIZE * self.RETAIN)\n",
    "   \n",
    "        self.pop = self.__generate_pop(self.SIZE)\n",
    "        self.best_individual = None\n",
    "        self.best_score = -math.inf\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        split_idx = int(len(X)*0.8)\n",
    "        \n",
    "        X_train = X[:split_idx]\n",
    "        y_train = y[:split_idx]\n",
    "        X_val = X[split_idx:]\n",
    "        y_val = y[split_idx:]\n",
    "        \n",
    "        for GENERATION in range(self.GENERATIONS):\n",
    "            # calculate score for each one\n",
    "            scored = [ (p, p.fitness(X_train, y_train, X_val, y_val)) for p in self.pop ]\n",
    "\n",
    "            # sort the population\n",
    "            sorted_pop = sorted(scored, key=lambda p: p[1], reverse=True)\n",
    "            \n",
    "            avg_fitness = sum([p[1] for p in sorted_pop])/float(self.SIZE)\n",
    "            \n",
    "            print(f'Average fitness {avg_fitness} on iteration {GENERATION}')\n",
    "\n",
    "            best = sorted_pop[0]\n",
    "\n",
    "            if best[1] > self.best_score:\n",
    "                self.best_score = best[1]\n",
    "                self.best_individual = best[0]\n",
    "\n",
    "            sorted_pop = [v[0] for v in sorted_pop[:self._retain_int]]\n",
    "\n",
    "            while len(sorted_pop) < self.SIZE:\n",
    "\n",
    "                idx_p1 = random.randint(0, self._retain_int-1)\n",
    "                idx_p2 = random.randint(0, self._retain_int-1)\n",
    "                while idx_p2 == idx_p1:\n",
    "                    idx_p2 = random.randint(0, self._retain_int-1)\n",
    "\n",
    "                new = self.recombine(sorted_pop[idx_p1], sorted_pop[idx_p2])\n",
    "\n",
    "                sorted_pop.append(new)\n",
    "\n",
    "            assert len(sorted_pop) == self.SIZE\n",
    "\n",
    "            self.pop = []\n",
    "            for i in sorted_pop:\n",
    "                if random.random() < self.MUTATION_RATE:\n",
    "                    self.pop.append(self.mutate(i))\n",
    "                else:\n",
    "                    self.pop.append(i)\n",
    "        \n",
    "        return self.best_individual, self.best_score\n",
    "    \n",
    "    \n",
    "    def recombine(self, p1, p2):\n",
    "        p1 = p1.config\n",
    "        p2 = p2.config\n",
    "        \n",
    "        split_idx = random.randint(0, len(p1))\n",
    "        \n",
    "        child = deepcopy(p1[:split_idx])\n",
    "        child += deepcopy(p2[split_idx:])\n",
    "        \n",
    "        return Individual(child)\n",
    "        \n",
    "    def mutate(self, p):\n",
    "        p = p.config\n",
    "        \n",
    "        idx = random.randint(0, len(p)-1) # selects on property to change\n",
    "        cur_value = p[idx]\n",
    "        \n",
    "        while p[idx] == cur_value:      # ensure we are changing\n",
    "            if idx < 5:\n",
    "                p[idx] = random.randint(0, 64)\n",
    "            else:\n",
    "                p[idx] = choice(ACTIVATIONS)\n",
    "                \n",
    "        return Individual(p)\n",
    "    \n",
    "    def __generate_pop(self, size):\n",
    "        pop = []\n",
    "        for _ in range(size):\n",
    "            pop.append(self.__generate_individual())\n",
    "            \n",
    "        return pop\n",
    "            \n",
    "\n",
    "    def __generate_individual(self):\n",
    "        return Individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images.\n",
    "X_train = (X_train / 255.) - 0.5\n",
    "X_test = (X_test / 255.) - 0.5\n",
    "\n",
    "# Flatten the images.\n",
    "X_train = X_train.reshape((-1, 784))\n",
    "X_test = X_test.reshape((-1, 784))\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111250042915344\n",
      "0.9232500195503235\n",
      "0.09852083027362823\n",
      "0.09950000047683716\n",
      "0.8321458101272583\n",
      "0.8356666564941406\n",
      "0.4372916519641876\n",
      "0.5059999823570251\n",
      "0.9510416388511658\n",
      "0.9555000066757202\n",
      "0.2084375023841858\n",
      "0.0925000011920929\n",
      "0.10252083092927933\n",
      "0.09558333456516266\n",
      "0.11395833641290665\n",
      "0.10599999874830246\n",
      "0.9416041374206543\n",
      "0.9485833048820496\n",
      "0.10616666823625565\n",
      "0.16333332657814026\n",
      "Average fitness 0.47028124108910563 on iteration 0\n",
      "0.9568958282470703\n",
      "0.9589166641235352\n",
      "0.9389166831970215\n",
      "0.9460833072662354\n",
      "0.9223541617393494\n",
      "0.9294166564941406\n",
      "0.8333333134651184\n",
      "0.8504999876022339\n",
      "0.5283750295639038\n",
      "0.6693333387374878\n",
      "0.9409583210945129\n",
      "0.9450833201408386\n",
      "0.9411875009536743\n",
      "0.9444166421890259\n",
      "0.8956041932106018\n",
      "0.9068333506584167\n",
      "0.9213958382606506\n",
      "0.9163333177566528\n",
      "0.7600833177566528\n",
      "0.7827500104904175\n",
      "Average fitness 0.8639104187488555 on iteration 1\n",
      "0.9557708501815796\n",
      "0.9599999785423279\n",
      "0.942104160785675\n",
      "0.9485833048820496\n",
      "0.9494583606719971\n",
      "0.9537500143051147\n",
      "0.9471666812896729\n",
      "0.9505833387374878\n",
      "0.9099583625793457\n",
      "0.9177500009536743\n",
      "0.9358333349227905\n",
      "0.9412500262260437\n",
      "0.9568125009536743\n",
      "0.9605000019073486\n",
      "0.9134583473205566\n",
      "0.918583333492279\n",
      "0.9402916431427002\n",
      "0.9474999904632568\n",
      "0.9358333349227905\n",
      "0.9445000290870667\n",
      "Average fitness 0.9386687576770782 on iteration 2\n",
      "0.9473124742507935\n",
      "0.9505000114440918\n",
      "0.9566041827201843\n",
      "0.9568333625793457\n",
      "0.942270815372467\n",
      "0.9484999775886536\n",
      "0.9434999823570251\n",
      "0.950166642665863\n",
      "0.9481458067893982\n",
      "0.9483333230018616\n",
      "0.9415416717529297\n",
      "0.9433333277702332\n",
      "0.9565416574478149\n",
      "0.9575833082199097\n",
      "0.9452499747276306\n",
      "0.9485833048820496\n",
      "0.476541668176651\n",
      "0.4830000102519989\n",
      "0.9430624842643738\n",
      "0.940416693687439\n",
      "Average fitness 0.9000770717859268 on iteration 3\n",
      "0.9558749794960022\n",
      "0.9580833315849304\n",
      "0.9567916393280029\n",
      "0.9604166746139526\n",
      "0.9449999928474426\n",
      "0.9480833411216736\n",
      "0.9503124952316284\n",
      "0.9551666378974915\n",
      "0.9434375166893005\n",
      "0.9484166502952576\n",
      "0.9533541798591614\n",
      "0.9539166688919067\n",
      "0.9533125162124634\n",
      "0.9518333077430725\n",
      "0.9412500262260437\n",
      "0.9459999799728394\n",
      "0.9466041922569275\n",
      "0.9483333230018616\n",
      "0.9409791827201843\n",
      "0.9465833306312561\n",
      "Average fitness 0.9486916720867157 on iteration 4\n",
      "0.9567499756813049\n",
      "0.9549999833106995\n",
      "0.9580625295639038\n",
      "0.9574999809265137\n",
      "0.9555208086967468\n",
      "0.9551666378974915\n",
      "0.9556249976158142\n",
      "0.9590833187103271\n",
      "0.9493958353996277\n",
      "0.953166663646698\n",
      "0.9446458220481873\n",
      "0.9524166584014893\n",
      "0.9431041479110718\n",
      "0.9474166631698608\n",
      "0.956208348274231\n",
      "0.9549999833106995\n",
      "0.9523333311080933\n",
      "0.9557499885559082\n",
      "0.9546458125114441\n",
      "0.9520000219345093\n",
      "Average fitness 0.9526291608810424 on iteration 5\n",
      "0.9573125243186951\n",
      "0.956166684627533\n",
      "0.9581458568572998\n",
      "0.9580000042915344\n",
      "0.11316666752099991\n",
      "0.1159166693687439\n",
      "0.9547291398048401\n",
      "0.9537500143051147\n",
      "0.956250011920929\n",
      "0.9578333497047424\n",
      "0.9566249847412109\n",
      "0.9584166407585144\n",
      "0.9522916674613953\n",
      "0.9575833082199097\n",
      "0.9537500143051147\n",
      "0.9542499780654907\n",
      "0.9571666717529297\n",
      "0.9580000042915344\n",
      "0.9552916884422302\n",
      "0.956333339214325\n",
      "Average fitness 0.8714729227125645 on iteration 6\n",
      "0.9578750133514404\n",
      "0.9602500200271606\n",
      "0.9571250081062317\n",
      "0.9543333053588867\n",
      "0.9550416469573975\n",
      "0.9494166374206543\n",
      "0.9559999704360962\n",
      "0.9586666822433472\n",
      "0.9556249976158142\n",
      "0.9554166793823242\n",
      "0.9543333053588867\n",
      "0.9566666483879089\n",
      "0.9557708501815796\n",
      "0.9586666822433472\n",
      "0.9569791555404663\n",
      "0.9597499966621399\n",
      "0.9532291889190674\n",
      "0.9516666531562805\n",
      "0.9554374814033508\n",
      "0.9578333497047424\n",
      "Average fitness 0.9557416617870331 on iteration 7\n",
      "0.953374981880188\n",
      "0.9520000219345093\n",
      "0.957729160785675\n",
      "0.9608333110809326\n",
      "0.9566666483879089\n",
      "0.9589166641235352\n",
      "0.9579583406448364\n",
      "0.9597499966621399\n",
      "0.9561041593551636\n",
      "0.956083357334137\n",
      "0.9541041851043701\n",
      "0.9574999809265137\n",
      "0.9558125138282776\n",
      "0.9516666531562805\n",
      "0.9558333158493042\n",
      "0.9549999833106995\n",
      "0.9541666507720947\n",
      "0.9589999914169312\n",
      "0.9521666765213013\n",
      "0.9591666460037231\n",
      "Average fitness 0.955391663312912 on iteration 8\n",
      "0.9581249952316284\n",
      "0.9570000171661377\n",
      "0.9522500038146973\n",
      "0.9526666402816772\n",
      "0.9590833187103271\n",
      "0.9556666612625122\n",
      "0.9581041932106018\n",
      "0.9594166874885559\n",
      "0.9561874866485596\n",
      "0.953000009059906\n",
      "0.4751666784286499\n",
      "0.5081666707992554\n",
      "0.9545000195503235\n",
      "0.9589999914169312\n",
      "0.06947916746139526\n",
      "0.06566666811704636\n",
      "0.9547291398048401\n",
      "0.9572499990463257\n",
      "0.9547916650772095\n",
      "0.956083357334137\n",
      "Average fitness 0.8192416667938233 on iteration 9\n"
     ]
    }
   ],
   "source": [
    "bi, bscore = a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9498166441917419"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26, 63, 25, 20, 53, 'tanh', 'softmax']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.pop[1].config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, activation='relu', input_shape=(784,)))\n",
    "\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.5748 - accuracy: 0.8343\n",
      "Epoch 2/4\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2685 - accuracy: 0.9213\n",
      "Epoch 3/4\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2168 - accuracy: 0.9361\n",
      "Epoch 4/4\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1828 - accuracy: 0.9461\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=4, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(26, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(63, activation='relu'))\n",
    "\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(53, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.8930 - accuracy: 0.7133 - val_loss: 0.4036 - val_accuracy: 0.8803\n",
      "Epoch 2/4\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3620 - accuracy: 0.8911 - val_loss: 0.3072 - val_accuracy: 0.9061\n",
      "Epoch 3/4\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2928 - accuracy: 0.9107 - val_loss: 0.2560 - val_accuracy: 0.9249\n",
      "Epoch 4/4\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2518 - accuracy: 0.9239 - val_loss: 0.2389 - val_accuracy: 0.9266\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=4, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
